{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ff638599",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b0b73745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Labels (y):\n",
      "[0 1 1 1 1]\n",
      "\n",
      "Features (X):\n",
      "[[0. 1.]\n",
      " [1. 1.]\n",
      " [0. 1.]\n",
      " [1. 1.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the number of data points\n",
    "n_samples = 1000\n",
    "\n",
    "# Define the probabilities for each class\n",
    "class_probs = [0.5, 0.5]\n",
    "\n",
    "# Generate the class labels\n",
    "y = np.random.choice([0, 1], size=n_samples, p=class_probs)\n",
    "\n",
    "# Generate binary features for each class\n",
    "X = np.zeros((n_samples, 2))\n",
    "\n",
    "# Define the probabilities for each feature given the class label\n",
    "feature_probs = [[[0.8, 0.2],  # For class 0\n",
    "                  [0.2, 0.8]],  # For class 1\n",
    "                 [[0.6, 0.4],  # For class 0\n",
    "                  [0.4, 0.6]]]  # For class 1\n",
    "\n",
    "# Generate the features based on the class labels\n",
    "for i in range(n_samples):\n",
    "    for j in range(2):\n",
    "        X[i, j] = np.random.choice([0, 1], p=feature_probs[y[i]][j])\n",
    "\n",
    "# Display the first few rows of the generated dataset\n",
    "print(\"Class Labels (y):\")\n",
    "print(y[:5])\n",
    "print(\"\\nFeatures (X):\")\n",
    "print(X[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1947048a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, testX, trainY, testY = train_test_split(X, y, test_size = 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "561b5d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    \n",
    "    def __init__(self, X, y, laplase = 0):\n",
    "        self.X = pd.DataFrame(X)\n",
    "        self.y = pd.DataFrame(y)\n",
    "        self.laplase = laplase\n",
    "        \n",
    "    def fit(self):\n",
    "        self.values = {}\n",
    "        for col in self.X.columns:\n",
    "            self.values[col] = {}\n",
    "            for value in self.X[col].unique():\n",
    "                self.values[col][value] = {}\n",
    "                for label in self.y[self.y.columns[0]].unique():\n",
    "                    count = ((self.X[col] == value) & (self.y[self.y.columns[0]] == label)).sum()\n",
    "                    self.values[col][value][label] = (count + self.laplase) / ((self.y[self.y.columns[0]] == label).sum() \n",
    "                                                                               + (self.laplase * len(self.X[col].unique())))  \n",
    "        return self.values\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X = pd.DataFrame(X)\n",
    "        output = {}\n",
    "        for index, row in X.iterrows():\n",
    "            output[str(index)] = {} \n",
    "            for label in self.y[self.y.columns[0]].unique():\n",
    "                prob = 1   \n",
    "                for col, val in row.items(): \n",
    "                    prob = prob * self.values[col][val][label]\n",
    "                output[str(index)][label] = prob * (self.y[self.y.columns[0]] == label).sum()\n",
    "        max_subkeys = []\n",
    "        for key, sub_dict in output.items():\n",
    "            max_subkey = max(sub_dict, key=sub_dict.get)\n",
    "            max_subkeys.append(max_subkey)   \n",
    "        return max_subkeys\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "            \n",
    "                   \n",
    "                    \n",
    "                    \n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "485894b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = NaiveBayes(trainX, trainY, laplase = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "50570dff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {0.0: {0: 0.7772277227722773, 1: 0.6262626262626263},\n",
       "  1.0: {0: 0.22277227722772278, 1: 0.37373737373737376}},\n",
       " 1: {1.0: {0: 0.7846534653465347, 1: 0.5732323232323232},\n",
       "  0.0: {0: 0.21534653465346534, 1: 0.42676767676767674}}}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a88e2ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = g.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f17d8b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[58 33]\n",
      " [44 65]]\n",
      "Precision: [0.56862745 0.66326531]\n",
      "Recall: [0.63736264 0.59633028]\n",
      "Accuracy: 0.615\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def confusion_matrix(y_true, y_pred, num_classes):\n",
    "    matrix = np.zeros((num_classes, num_classes), dtype=int)\n",
    "    for true, pred in zip(y_true, y_pred):\n",
    "        matrix[int(true), int(pred)] += 1\n",
    "    return matrix\n",
    "\n",
    "def precision_recall_accuracy(conf_matrix):\n",
    "    num_classes = conf_matrix.shape[0]\n",
    "    precision = np.zeros(num_classes)\n",
    "    recall = np.zeros(num_classes)\n",
    "    accuracy = np.trace(conf_matrix) / np.sum(conf_matrix)\n",
    "    for i in range(num_classes):\n",
    "        true_positives = conf_matrix[i, i]\n",
    "        false_positives = np.sum(conf_matrix[:, i]) - true_positives\n",
    "        false_negatives = np.sum(conf_matrix[i, :]) - true_positives\n",
    "        precision[i] = true_positives / (true_positives + false_positives)\n",
    "        recall[i] = true_positives / (true_positives + false_negatives)\n",
    "    return precision, recall, accuracy\n",
    "\n",
    "\n",
    "conf_matrix = confusion_matrix(np.array(testY), s, 2)\n",
    "precision, recall, accuracy = precision_recall_accuracy(conf_matrix)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
